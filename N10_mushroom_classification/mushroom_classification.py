# -*- coding: utf-8 -*-
"""Mushroom_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kwpMPR8BNFXp7Ds0gJnerED-BSWOm_nG

# PHÂN LOẠI NẤM

# Python libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, roc_curve
from sklearn.tree import DecisionTreeClassifier, export_graphviz
import graphviz
from sklearn.model_selection import cross_val_predict, cross_val_score

"""# Đọc và phân tích bộ dữ liệu"""

from google.colab import drive
drive.mount('/content/drive/')

df = pd.read_csv('/content/drive/MyDrive/Mushroom_Classification/source_code/data/mushrooms.csv')

#Hiển thị thuộc tính các cột trong data
df.columns

#Hiển thị 5 hàng đầu tiên của data
df.head()

print("Dữ liệu gốc:", df.shape)

df['class'].value_counts()

#Visualize mô hình đếm số lượng nấm ăn được và không ăn được trong data
count = df['class'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6,5))
sns.barplot(count.index, count.values, alpha=0.6, palette="prism")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Class', fontsize=12)
plt.title('edible / poisonous')
#plt.savefig("count_class.jpeg", format='jpeg', dpi=100)
plt.show()

"""Nhận xét: Nhìn vào biểu đồ trên, chúng ta nhận thấy tập dữ liệu này cân bằng"""

#Visualize mô hình đếm số lượng 
count = df['cap-shape'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Accent")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Cap Shape', fontsize=12)
plt.title('convex / flat / knobbed / bell / sunken / conical')
#plt.savefig("count_cap_shape.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['cap-surface'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6,5))
sns.barplot(count.index, count.values, alpha=1, palette="Accent_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Cap Surface', fontsize=12)
plt.title('scaly / smooth / fibrous / grooves')
#plt.savefig("count_cap_surface.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['cap-color'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(8,5))
sns.barplot(count.index, count.values, alpha=1, palette="Accent")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Cap Color', fontsize=12)
plt.title('brown / gray / red / yellow / white / buff / pink / cinnamon / purple / green')
#plt.savefig("count_cap_color.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['bruises'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6,5))
sns.barplot(count.index, count.values, alpha=1, palette="Blues")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Bruises', fontsize=12)
plt.title('no / bruises')
#plt.savefig("count_bruises.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['odor'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(7.5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set2")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Odor', fontsize=12)
plt.title('none / foul / fishy / spicy / almond / anise / pungent / creosote / musty')
#plt.savefig("count_odor.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['gill-attachment'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set2_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Gill Attachment', fontsize=12)
plt.title('free / attached')
#plt.savefig("count_gill_attachment.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['gill-spacing'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set3_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Gill Spacing', fontsize=12)
plt.title('close / crowded')
#plt.savefig("count_gill_spacing.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['gill-size'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6,5))
sns.barplot(count.index, count.values, alpha=1, palette="Spectral")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Gill Size', fontsize=12)
plt.title('broad / narrow')
#plt.savefig("count_gill_size.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['gill-color'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(10,5))
sns.barplot(count.index, count.values, alpha=0.9, palette="CMRmap")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Gill Color', fontsize=12)
plt.title('buff / pink / white / brown / gray / chocolate / purple / black / red / yellow / orange / green')
#plt.savefig("count_gill_color.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['stalk-shape'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6,5))
sns.barplot(count.index, count.values, alpha=1, palette="YlGn")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Stalk Shape', fontsize=12)
plt.title('tapering / enlarging')
#plt.savefig("count_stalk_shape.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['stalk-root'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Spectral")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Stalk Root', fontsize=12)
plt.title('bulbous / missing / equal / club / rooted')
#plt.savefig("count_stalk_root.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['stalk-surface-above-ring'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(4.5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Spectral_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Stalk Surface Above Ring', fontsize=12)
plt.title('smooth / silky / fibrous / scaly')
#plt.savefig("count_stalk_surface_above_ring.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['stalk-surface-below-ring'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(4.5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Spectral")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Stalk Surface Below Ring', fontsize=12)
plt.title('smooth / silky / fibrous / scaly')
#plt.savefig("count_stalk_surface_below_ring.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['stalk-color-above-ring'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(7,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set1_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Stalk Color Above Ring', fontsize=12)
plt.title('white / pink / gray / brown / buff / orange / red / cinnamon / yellow')
#plt.savefig("count_stalk_color_above_ring.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['stalk-color-below-ring'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6.5,5))
sns.barplot(count.index, count.values, alpha=0.8, palette="Set2")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Stalk Color Below Ring', fontsize=12)
plt.title('white / pink / gray / brown / buff / orange / cinnamon / yellow')
#plt.savefig("count_stalk_color_below_ring.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['veil-type'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set1_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Veil Type', fontsize=12)
plt.title('partial')
#plt.savefig("count_veil_type.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['veil-color'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(4.5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set1_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Veil Color', fontsize=12)
plt.title('white / brown / orange / yellow')
#plt.savefig("count_veil_color.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['ring-number'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(5.5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set1_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Ring Number', fontsize=12)
plt.title('one / two / none')
#plt.savefig("count_ring_number.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['ring-type'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set1")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Ring Type', fontsize=12)
plt.title('pendant / evanescent / large / laring / none')
#plt.savefig("count_ring_type.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['spore-print-color'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(7.5,5))
sns.barplot(count.index, count.values, alpha=1, palette="Set2")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Spore Print Color', fontsize=12)
plt.title('white / brown / black / chocolate / green / yellow / buff / purple / orange')
#plt.savefig("count_spore_print_color.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['population'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(7,5))
sns.barplot(count.index, count.values, alpha=0.6, palette="brg")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Population', fontsize=12)
plt.title('several / solitary / scattered / numerous / abundant / clustered')
#plt.savefig("count_population.jpeg", format='jpeg', dpi=100)
plt.show()

#Visualize mô hình đếm số lượng 
count = df['habitat'].value_counts()
sns.set_context(font_scale=1.5)
plt.figure(figsize=(6.5,5))
sns.barplot(count.index, count.values, alpha=0.9, palette="brg_r")
plt.ylabel('Count', fontsize=12)
plt.xlabel('Habitat', fontsize=12)
plt.title('woods / grasses / paths / leaves / urban / meadows / waste')
#plt.savefig("count_habitat.jpeg", format='jpeg', dpi=100)
plt.show()

"""Dữ liệu mang tính phân loại vì vậy chúng ta chuyển đổi nó bằng Bộ mã hóa nhãn LabelEncoder() để chuyển sang số."""

#Mã hóa nhãn (chuyển đổi dữ liệu chữ thành số)
labelencoder=LabelEncoder()
for column in df.columns:
    df[column] = labelencoder.fit_transform(df[column])

#Mã hóa nhãn (chuyển đổi dữ liệu chữ thành số)
mappings = list()
encoder = LabelEncoder()
for column in range(len(df.columns)):
    df[df.columns[column]] = encoder.fit_transform(df[df.columns[column]])
    mappings_dict = {index: label for index, label in enumerate(encoder.classes_)}
    mappings.append(mappings_dict)

#Biến đổi chữ thành số tương ứng
mappings

#Xem số liệu sau khi mã hóa data
df.describe()

df.head()
#df.tail()

#Kiểm tra cột veil-type
df['veil-type']

"""Nhìn vào các bảng số liệu trên có thể thấy rằng cột "veil-type" bằng 0 và không đóng góp vào việc phân loại dữ liệu nên chúng ta có thể loại bỏ nó."""

#Loại bỏ cột veil-type khỏi tập dữ liệu đang xét
df=df.drop(["veil-type"],axis=1)

"""Biểu đồ violin dưới đây thể hiện sự phân bố của các đặc điểm phân loại. Có thể thấy đặc tính "gill-color" của nấm chia làm hai phần, 3 trên và 3 dưới, có thể góp phần vào việc phân loại."""

#Visualize biểu đồ Violin
df_div = pd.melt(df, "class", var_name="Characteristics")
fig, ax = plt.subplots(figsize=(16,6))
p = sns.violinplot(ax = ax, x="Characteristics", y="value", hue="class", split = True, data=df_div, inner = 'quartile', palette = 'Set2')
df_no_class = df.drop(["class"],axis = 1)
p.set_xticklabels(rotation = 90, labels = list(df_no_class.columns));
#plt.savefig("violinplot.png", format='png', dpi=100, bbox_inches='tight')
plt.show()

"""Xét mối tương quan giữa các biến:"""

#Visualize mô hình thể hiện mối tương quan giữa các thuộc tính
plt.figure(figsize=(14,12))
sns.heatmap(df.corr(),linewidths=.1,cmap="YlGnBu", annot=True, annot_kws={"size": 8})
plt.yticks(rotation=0);
#plt.savefig("corr.png", format='png', dpi=100, bbox_inches='tight')
plt.show()

"""Nhận xét: Thông thường biến ít tương quan nhất là biến quan trọng nhất để phân loại. Trong trường hợp này, "gill-color" = -0,53. Vì vậy chúng ta hãy xem xét kỹ nó:"""

df[['class', 'gill-color']].groupby(['gill-color'], as_index=False).mean().sort_values(by='class', ascending=False)

#Visualize thuộc tính "gill-color" trong bảng trên bằng biểu đồ
new_var=df[['class', 'gill-color']]
new_var=new_var[new_var['gill-color']<=3.5]
sns.factorplot('class', col='gill-color', data=new_var, kind='count', size=3.5, aspect=.8, col_wrap=4,palette="bwr");
#plt.savefig("gillcolor1.png", format='png', dpi=100, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

new_var=df[['class', 'gill-color']]
new_var=new_var[new_var['gill-color']>3.5]
sns.factorplot('class', col='gill-color', data=new_var, kind='count', size=3.5, aspect=.8, col_wrap=4,palette="bwr");
#plt.savefig("gillcolor2.png", format='png', dpi=100, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

"""Cây quyết định"""

#Xử lý dữ liệu để vẽ cây quyết định
X_dt = df.drop(['class'], axis=1)  
Y = df["class"]
X_train_dt, X_test_dt, Y_train_dt, Y_test_dt = train_test_split(X_dt, Y, random_state=42, test_size=0.3) #train 70% - test 30%

def train_and_test(model, train_data, test_data):
    """
    Trains the model on the training data, prints the score for such model evaluating it on the testing data
    and also returns the learned model
    model: classifier to be used
    train_data: [X_train_dt, Y_train_dt]
    test_data: [X_test_dt, Y_test_dt]
    """
    # Fits the model to the training data 
    model.fit(train_data[0], train_data[1])
    # Evaluates the model using the testing data
    print(model.score(test_data[0], test_data[1]))
    # Returns the fitted model
    return model

from sklearn.tree import DecisionTreeClassifier as clf
Y_name = ['e','p']
clf = DecisionTreeClassifier()
clf.fit(X_train_dt, Y_train_dt)
Y_pred_dt = clf.predict(X_test_dt)
dot_data = export_graphviz(clf, out_file=None, 
                         feature_names=X_dt.columns,
                         class_names=Y_name, 
                         filled=True, rounded=True,  
                         special_characters=True)  
graph = graphviz.Source(dot_data)
#graph.render(filename='DecisionTree')
graph

"""Nhận xét: Nhìn vào cây quyết định của bộ dữ liệu, ta thấy rằng "gill-color" là nút gốc của cây"""

#Visualize biểu đồ thể hiện các đặc tính quan trọng trong bộ dữ liệu Mushrooms
features_list = X_dt.columns.values
feature_importance = clf.feature_importances_
sorted_idx = np.argsort(feature_importance)

plt.figure(figsize=(6,5))
plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')
plt.yticks(range(len(sorted_idx)), features_list[sorted_idx])
plt.xlabel('Importance')
plt.title('Feature importances')
plt.draw()
#plt.savefig("featureimp.png", format='png', dpi=100, bbox_inches='tight')
plt.show()

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('Decision Tree Classifier Report:\n\n{}\n'.format(classification_report(Y_test_dt, Y_pred_dt)))
res = cross_val_score(clf, X_test_dt,Y_test_dt, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(Y_test_dt,clf.predict(X_test_dt))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(clf.score(X_test_dt, Y_test_dt)*100, 2)))

"""Bằng tất cả các phương pháp đã được kiểm tra phía trên. Chúng ta nhận thấy đặc điểm quan trọng nhất là "gill-color"

# Xử lý bộ dữ liệu
"""

X=pd.get_dummies(X_dt,columns=X_dt.columns,drop_first=True)
X.head()

"""Chia dữ liệu: 70% training; 30% test"""

from sklearn.model_selection import train_test_split
from sklearn import preprocessing

#Chia dữ liệu thành các nhóm train và test
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42) #70% training and 30% test
#Chuẩn hóa tập dữ liệu x_train và x_test
sc = preprocessing.StandardScaler().fit(X_train)
X_scaled = sc.transform(X)
X_train_scaled = sc.fit_transform(X_train)
X_test_scaled = sc.transform(X_test)

print(X_dt)

print(X)

#Cột class
print(Y)

#PCA giảm chiều dữ liệu
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train_scaled) 
X_test_pca = pca.transform(X_test_scaled)

#Visualize mô hình dữ liệu Data Mushrooms bằng PCA
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

#X_scaled
X_pca = pca.fit_transform(X_scaled)
e_x = X_pca[(Y==0)]
p_x = X_pca[(Y==1)]

#Visualize mô hình PCA
plt.figure(figsize=(9,6))
plt.title('Data Mushrooms PCA '+ str(X_pca.shape))
plt.scatter(p_x[:,0],p_x[:,1],marker='o',alpha=0.6)
plt.scatter(e_x[:,0],e_x[:,1],marker='x',alpha=0.6)
plt.legend(['Class p','Class e'])
#plt.savefig('data_mushrooms_pca.png', format='png', dpi=100, bbox_inches='tight')
plt.show()

print("Dữ liệu gốc sau khi xử lý:", X_pca.shape)

#Visualize 2 mô hình dữ liệu train và test sau khi chuẩn hóa bằng PCA
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

#X_train_scaled
e_train = X_train_pca[(Y_train==0)]
p_train = X_train_pca[(Y_train==1)]

#X_test_scaled
e_test = X_test_pca[(Y_test==0)]
p_test = X_test_pca[(Y_test==1)]

#Visualize mô hình PCA
fig, (plttrain, plttest) = plt.subplots(1, 2)
#PCA Train
plttrain.set_title('Train data PCA '+ str(X_train_pca.shape))
plttrain.scatter(p_train[:,0],p_train[:,1],alpha=0.2, color='orange', marker='o')
plttrain.scatter(e_train[:,0],e_train[:,1],alpha=0.3, color='c', marker='+')
plttrain.legend(['Class p','Class e'])
#PCA test data
plttest.set_title('Test data PCA '+ str(X_test_pca.shape))
plttest.scatter(p_test[:,0], p_test[:,1],alpha=0.2, marker='o')
plttest.scatter(e_test[:,0], e_test[:,1],alpha=0.3, color='r', marker='+')
plttest.legend(['Class p','Class e'])
#plt.savefig('train-test_data_pca.png', format='png', dpi=150, bbox_inches='tight')
plt.show()

#Visualize mô hình dữ liệu Train Data sau khi chuẩn hóa bằng PCA
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

#Giảm chiều dữ liệu
e_train = X_train_pca[(Y_train==0)]
p_train = X_train_pca[(Y_train==1)]

#Visualize mô hình 
plt.figure(figsize=(6.5,4.5))
plt.title('Train data PCA '+ str(X_train_pca.shape))
plt.scatter(e_train[:, 0], e_train[:, 1], color='c', alpha=0.2)
plt.scatter(p_train[:, 0], p_train[:, 1], color='orange', alpha=0.2)
plt.legend(['Class p','Class e'])
#plt.savefig('train_data_pca.png', format='png', dpi=100, bbox_inches='tight')
plt.show()

print("Dữ liệu đào tạo sau khi chuẩn hóa:", X_train_pca.shape)

#Visualize mô hình dữ liệu Test Data sau khi chuẩn hóa bằng PCA
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

#Giảm chiều dữ liệu
e_test = X_test_pca[(Y_test==0)]
p_test = X_test_pca[(Y_test==1)]

#Visualize mô hình PCA
plt.figure(figsize=(6.5,4.5))
plt.title('Test data PCA '+ str(X_test_pca.shape))
plt.scatter(e_test[:, 0], e_test[:, 1],color='r', alpha=0.2)
plt.scatter(p_test[:, 0], p_test[:, 1], alpha=0.2)
plt.legend(['Class p','Class e'])
#plt.savefig('test_data_pca.png', format='png', dpi=100, bbox_inches='tight')
plt.show()

print("Dữ liệu thử nghiệm sau khi chuẩn hóa:", X_test_pca.shape)

"""Đối với bộ dữ liệu phân loại nấm, nhóm chúng em đã chọn một số thuật toán phân loại đã học để tính toán và phân tích. Chúng em đã sử dụng các thư viện của trình phân loại trong Python và giải thích cách hoạt động của nó.

Bước tiếp theo, ta tiến hành xây dựng model để dự đoán và ước tính kết quả

# Decision Tree
"""

from sklearn.tree import DecisionTreeClassifier as DT
dt = DT(criterion='entropy',random_state=42)
dt.fit(X_train_pca, Y_train)

Y_pred_dt = dt.predict(X_test_pca)

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('Decision Tree Classifier Report:\n\n{}\n'.format(classification_report(Y_test, Y_pred_dt)))
res = cross_val_score(dt, X_test_pca, Y_test, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(Y_test,dt.predict(X_test_pca))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(dt.score(X_test_pca, Y_test)*100, 2)))

#Visualize Confusion Matrix (Ma trận hỗn hợp)
cfm_dt = confusion_matrix(Y_test, Y_pred_dt)
x_axis_labels = ["Edible", "Poisonous"]
y_axis_labels = ["Edible", "Poisonous"]

f, ax = plt.subplots(figsize =(6,6))
sns.heatmap(cfm_dt, annot = True, linewidths=0.2, linecolor="black", fmt = ".0f", ax=ax, xticklabels=x_axis_labels, yticklabels=y_axis_labels)
plt.title('Decision Tree Classifier confusion matrix')
plt.ylabel('TRUE LABEL')
plt.xlabel('PREDICTED LABEL');
plt.savefig("dtcm.png", format='png', dpi=150, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

#Visualize đồ thị đường cong PR (Precision-Recall Curves)
precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred_dt)
area = auc(recall, precision)
plt.figure()
plt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)
plt.legend(loc = 'lower left')
plt.title('Precision-Recall Curves of Decision Tree')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([-0.1, 1.1])
plt.xlim([-0.1, 1.1])
#plt.savefig("dtpr.png", format='png', dpi=150, bbox_inches='tight')
plt.show()

#Visualize mô hình Decision Tree Test Set
#dt_pca = DT()
#dt_pca.fit(X_train_pca,Y_train)

plt.figure(figsize=(10,7))
from matplotlib.colors import ListedColormap
X_set, Y_set = X_test_pca, Y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, dt.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.6, cmap = ListedColormap(('lightcoral', 'mediumslateblue')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i,j in enumerate(np.unique(Y_set)):
    plt.scatter(X_set[Y_set == j, 0], X_set[Y_set == j, 1],
                c = ListedColormap(('lightcoral', 'mediumslateblue'))(i), label = j)
plt.title("Decision Tree Test Set")
plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.legend()
#plt.savefig("dt_pci_test.png", format='png', dpi=100, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

"""# Naïve Bayes"""

from sklearn.naive_bayes import GaussianNB as NB
nb = NB()
nb.fit(X_train_pca,Y_train)

Y_pred_nb = nb.predict(X_test_pca)

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('Naïve Bayes Classifier report:\n\n{}\n'.format(classification_report(Y_test, Y_pred_nb)))
res = cross_val_score(nb, X_test_pca, Y_test, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(Y_test,nb.predict(X_test_pca))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(nb.score(X_test_pca, Y_test)*100, 2)))

#Visualize Confusion Matrix (Ma trận hỗn hợp)
cfm_nb = confusion_matrix(Y_test, Y_pred_nb)

x_axis_labels = ["Edible", "Poisonous"]
y_axis_labels = ["Edible", "Poisonous"]

f, ax = plt.subplots(figsize =(6,6))
sns.heatmap(cfm_nb, annot = True, linewidths=0.2, linecolor="black", fmt = ".0f", ax=ax, xticklabels=x_axis_labels, yticklabels=y_axis_labels)
plt.title('Naïve Bayes Classifier confusion matrix')
plt.ylabel('TRUE LABEL')
plt.xlabel('PREDICTED LABEL');
#plt.savefig("nbcm.png", format='png', dpi=150, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

#Visualize đồ thị đường cong PR (Precision-Recall Curves)
precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred_nb)
area = auc(recall, precision)
plt.figure()
plt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)
plt.legend(loc = 'lower left')
plt.title('Precision-Recall Curves of Naïve Bayes')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([-0.1, 1.1])
plt.xlim([-0.1, 1.1])
#plt.savefig("nbpr.png", format='png', dpi=150, bbox_inches='tight')
plt.show()

#Visualize mô hình Naïve Bayes Test Set
#nb_pca = NB()
#nb_pca.fit(X_train_pca,Y_train)

plt.figure(figsize=(10,7))
from matplotlib.colors import ListedColormap
X_set, Y_set = X_test_pca, Y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, nb.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.6, cmap = ListedColormap(('lightcoral', 'mediumslateblue')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i,j in enumerate(np.unique(Y_set)):
    plt.scatter(X_set[Y_set == j, 0], X_set[Y_set == j, 1],
                c = ListedColormap(('lightcoral', 'mediumslateblue'))(i), label = j)
plt.title("Naïve Bayes Test Set")
plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.legend()
#plt.savefig("nb_pci_test.png", format='png', dpi=100, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier as RF
rf = RF(n_estimators = 50, criterion = 'entropy', random_state = 42)
rf.fit(X_train_pca, Y_train)

Y_pred_rf = rf.predict(X_test_pca)

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('Random Forest Classifier report:\n\n{}\n'.format(classification_report(Y_test, Y_pred_rf)))
res = cross_val_score(rf, X_test_pca, Y_test, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(Y_test,rf.predict(X_test_pca))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(rf.score(X_test_pca, Y_test)*100, 2)))

#Visualize Confusion Matrix (Ma trận hỗn hợp)
cfm_rf = confusion_matrix(Y_test, Y_pred_rf)

x_axis_labels = ["Edible", "Poisonous"]
y_axis_labels = ["Edible", "Poisonous"]

f, ax = plt.subplots(figsize =(6,6))
sns.heatmap(cfm_rf, annot = True, linewidths=0.2, linecolor="black", fmt = ".0f", ax=ax, xticklabels=x_axis_labels, yticklabels=y_axis_labels)
plt.title('Random Forest Classifier confusion matrix')
plt.ylabel('TRUE LABEL')
plt.xlabel('PREDICTED LABEL');
#plt.savefig("rfcm.png", format='png', dpi=150, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

#Visualize đồ thị đường cong PR (Precision-Recall Curves)
precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred_rf)
area = auc(recall, precision)
plt.figure()
plt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)
plt.legend(loc = 'lower left')
plt.title('Precision-Recall Curves of Random Forest')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([-0.1, 1.1])
plt.xlim([-0.1, 1.1])
#plt.savefig("rfpr.png", format='png', dpi=150, bbox_inches='tight')
plt.show()

#Visualize mô hình Random Forest Classifier Test Set
#rf_pca = RF()
#rf_pca.fit(X_train_pca,Y_train)

plt.figure(figsize=(10,7))
from matplotlib.colors import ListedColormap
X_set, Y_set = X_test_pca, Y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, rf.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.6, cmap = ListedColormap(('lightcoral', 'mediumslateblue')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i,j in enumerate(np.unique(Y_set)):
    plt.scatter(X_set[Y_set == j, 0], X_set[Y_set == j, 1],
                c = ListedColormap(('lightcoral', 'mediumslateblue'))(i), label = j)
plt.title("Random Forest Test Set")
plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.legend()
#plt.savefig("rf_pci_test.png", format='png', dpi=100, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

"""# Support Vector Machines"""

from sklearn.svm import SVC
svm = SVC(random_state=42, gamma="auto", probability=True)
svm.fit(X_train_pca,Y_train)

Y_pred_svm = svm.predict(X_test_pca)

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('Support Vector Machines report:\n\n{}\n'.format(classification_report(Y_test, Y_pred_svm)))
res = cross_val_score(svm, X_test_pca, Y_test, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(Y_test,svm.predict(X_test_pca))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(svm.score(X_test_pca, Y_test)*100, 2)))

#Visualize Confusion Matrix (Ma trận hỗn hợp)
cfm_svm = confusion_matrix(Y_test, Y_pred_svm)

x_axis_labels = ["Edible", "Poisonous"]
y_axis_labels = ["Edible", "Poisonous"]

f, ax = plt.subplots(figsize =(6,6))
sns.heatmap(cfm_svm, annot = True, linewidths=0.2, linecolor="black", fmt = ".0f", ax=ax, xticklabels=x_axis_labels, yticklabels=y_axis_labels)
plt.title('Support Vector Machines confusion matrix')
plt.ylabel('TRUE LABEL')
plt.xlabel('PREDICTED LABEL');
#plt.savefig("svmcm.png", format='png', dpi=150, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

#Visualize đồ thị đường cong PR (Precision-Recall Curves)
precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred_svm)
area = auc(recall, precision)
plt.figure()
plt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)
plt.legend(loc = 'lower left')
plt.title('Precision-Recall Curves of Support Vector Machines')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([-0.1, 1.1])
plt.xlim([-0.1, 1.1])
#plt.savefig("svmpr.png", format='png', dpi=150, bbox_inches='tight')
plt.show()

#Visualize mô hình Support Vector Machines Test Set
#svm_pca = SVC()
#svm_pca.fit(X_train_pca,Y_train)

plt.figure(figsize=(10,7))
from matplotlib.colors import ListedColormap
X_set, Y_set = X_test_pca, Y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, svm.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.6, cmap = ListedColormap(('lightcoral', 'mediumslateblue')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i,j in enumerate(np.unique(Y_set)):
    plt.scatter(X_set[Y_set == j, 0], X_set[Y_set == j, 1],
                c = ListedColormap(('lightcoral', 'mediumslateblue'))(i), label = j)
plt.title("Support Vector Machines Test Set")
plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.legend()
#plt.savefig("svm_pci_test.png", format='png', dpi=100, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

"""# K-Nearest Neighbors"""

from sklearn.neighbors import KNeighborsClassifier as KNN
knn = KNN()
knn.fit(X_train_pca,Y_train)

Y_pred_knn = knn.predict(X_test_pca)

from sklearn.model_selection import cross_val_predict, cross_val_score

print("TEST RESULTS:\n")
#Report
print('K-Nearest Neighbors report:\n\n{}\n'.format(classification_report(Y_test, Y_pred_knn)))
res = cross_val_score(knn, X_test_pca, Y_test, cv=10, n_jobs=-1, scoring='accuracy')
#Độ chính xác trung bình
print('Average Accuracy:\t{0:.4f}\n'.format((res.mean())))
#Độ lệch chuẩn
print('Standard Deviation:\t{0:.4f}\n'.format(res.std()))
#Ma trận hỗn hợp
print('Confusion Matrix:\n{}\n'.format(confusion_matrix(Y_test,knn.predict(X_test_pca))))
#Điểm chính xác
print("Accuracy Score:\t\t{}%".format(round(knn.score(X_test_pca, Y_test)*100, 2)))

#Visualize Confusion Matrix (Ma trận hỗn hợp)
cfm_knn = confusion_matrix(Y_test, Y_pred_knn)

x_axis_labels = ["Edible", "Poisonous"]
y_axis_labels = ["Edible", "Poisonous"]

f, ax = plt.subplots(figsize =(6,6))
sns.heatmap(cfm_knn, annot = True, linewidths=0.2, linecolor="black", fmt = ".0f", ax=ax, xticklabels=x_axis_labels, yticklabels=y_axis_labels)
plt.title('K-Nearest Neighbors confusion matrix')
plt.ylabel('TRUE LABEL')
plt.xlabel('PREDICTED LABEL');
#plt.savefig("knncm.png", format='png', dpi=150, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

#Visualize đồ thị đường cong PR (Precision-Recall Curves)
precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred_knn)
area = auc(recall, precision)
plt.figure()
plt.plot(recall, precision, label = 'Area Under Curve = %0.3f'% area)
plt.legend(loc = 'lower left')
plt.title('Precision-Recall Curves of K-Nearest Neighbors')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([-0.1, 1.1])
plt.xlim([-0.1, 1.1])
#plt.savefig("knnpr.png", format='png', dpi=150, bbox_inches='tight')
plt.show()

#Visualize mô hình K-Nearest Neighbors Test Set
#knn_pca = KNN()
#knn_pca.fit(X_train_pca,Y_train)

plt.figure(figsize=(10,7))
from matplotlib.colors import ListedColormap
X_set, Y_set = X_test_pca, Y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, knn.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.6, cmap = ListedColormap(('lightcoral', 'mediumslateblue')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i,j in enumerate(np.unique(Y_set)):
    plt.scatter(X_set[Y_set == j, 0], X_set[Y_set == j, 1],
                c = ListedColormap(('lightcoral', 'mediumslateblue'))(i), label = j)
plt.title("K-Nearest Neighbors Test Set")
plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.legend()
#plt.savefig("knn_pci_test.png", format='png', dpi=100, bbox_inches='tight')
plt.show()
#(edible:0 poisonous:1)

"""# ROC Curves"""

#Visualize mô hình ROC (Receiver Operating Characteristic) Curves - so sánh trực quan các mô hình phân loại
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, accuracy_score

plt.figure(figsize=(12,9))
models = [
{
    'label': 'Decision Tree',
    'model': dt,
},
{
    'label': 'Naïve Bayes',
    'model': nb,
},
{
    'label': 'Random Forest',
    'model': rf,
},
{
    'label': 'Support Vector Machine',
    'model': svm,
},
{
    'label': 'K-Nearest Neighbors',
    'model': knn,
}
]

for m in models:
    model = m['model'] 
    model.fit(X_train_pca, Y_train) 
    y_pred=model.predict(X_test_pca) 
    fpr, tpr, thresholds = roc_curve(Y_test, model.predict_proba(X_test_pca)[:,1])
    auc = roc_auc_score(Y_test,model.predict(X_test_pca))
    plt.plot(fpr, tpr, linestyle='-', linewidth=3, label='%s ROC (area = %0.2f)' % (m['label'], auc))

plt.plot([0, 1], [0, 1],'b--', linewidth=3)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('1 - Specificity (False Positive Rate)', fontsize=15)
plt.ylabel('Sensitivity (True Positive Rate)', fontsize=15)
plt.title('Receiver Operating Characteristic (ROC)', fontsize=15)
plt.legend(loc="lower right", fontsize=14)
#plt.savefig("roc_curves.png", format='png', dpi=100, bbox_inches='tight')
plt.show()